{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from predict.prediction_models import (\n",
    "    DensePredictor,\n",
    "    ConvPredictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_predictor = DensePredictor(with_features=True)\n",
    "conv_predictor = ConvPredictor(with_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_wo_features_predictor = DensePredictor(with_features=False)\n",
    "conv_wo_features_predictor = ConvPredictor(with_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_name = 'V100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block1_conv1: {'batchsize': 64, 'matsize': 224, 'kernelsize': 3, 'channels_in': 3, 'channels_out': 64, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block1_conv2: {'batchsize': 64, 'matsize': 224, 'kernelsize': 3, 'channels_in': 64, 'channels_out': 64, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block2_conv1: {'batchsize': 64, 'matsize': 112, 'kernelsize': 3, 'channels_in': 64, 'channels_out': 128, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block2_conv2: {'batchsize': 64, 'matsize': 112, 'kernelsize': 3, 'channels_in': 128, 'channels_out': 128, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block3_conv1: {'batchsize': 64, 'matsize': 56, 'kernelsize': 3, 'channels_in': 128, 'channels_out': 256, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block3_conv2: {'batchsize': 64, 'matsize': 56, 'kernelsize': 3, 'channels_in': 256, 'channels_out': 256, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block3_conv3: {'batchsize': 64, 'matsize': 56, 'kernelsize': 3, 'channels_in': 256, 'channels_out': 256, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block4_conv1: {'batchsize': 64, 'matsize': 28, 'kernelsize': 3, 'channels_in': 256, 'channels_out': 512, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block4_conv2: {'batchsize': 64, 'matsize': 28, 'kernelsize': 3, 'channels_in': 512, 'channels_out': 512, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block4_conv3: {'batchsize': 64, 'matsize': 28, 'kernelsize': 3, 'channels_in': 512, 'channels_out': 512, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block5_conv1: {'batchsize': 64, 'matsize': 14, 'kernelsize': 3, 'channels_in': 512, 'channels_out': 512, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block5_conv2: {'batchsize': 64, 'matsize': 14, 'kernelsize': 3, 'channels_in': 512, 'channels_out': 512, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n",
      "block5_conv3: {'batchsize': 64, 'matsize': 14, 'kernelsize': 3, 'channels_in': 512, 'channels_out': 512, 'strides': 1, 'padding': 1, 'activation_fct': 'ReLU', 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store the features of each convolutional layer\n",
    "vgg16_conv_layers = {}\n",
    "vgg16_dense_layers = {}\n",
    "batch_size = 64\n",
    "dataset_size = 1048\n",
    "\n",
    "# Helper function to add layer details to the dictionary\n",
    "def add_conv_layer_vgg(layer_name, matrix_size, kernel_size, channels_in, channels_out, strides, padding, activation, optimizer):\n",
    "    vgg16_conv_layers[layer_name] = {\n",
    "        'batchsize': batch_size,\n",
    "        'matsize': matrix_size,\n",
    "        'kernelsize': kernel_size,\n",
    "        'channels_in': channels_in,\n",
    "        'channels_out': channels_out,\n",
    "        'strides': strides,\n",
    "        'padding': padding,\n",
    "        'activation_fct': activation,\n",
    "        'optimizer': optimizer\n",
    "    }\n",
    "    \n",
    "def add_dense_layer_vgg(layer_name, input_size, output_size, activation, optimizer):\n",
    "    vgg16_dense_layers[layer_name] = {\n",
    "        'batchsize': batch_size,\n",
    "        'dim_input': input_size,\n",
    "        'dim_output': output_size,\n",
    "        'activation_fct': activation,\n",
    "        'optimizer': optimizer\n",
    "    }\n",
    "\n",
    "# Block 1: 2 Conv layers + Max Pooling\n",
    "add_conv_layer_vgg(\"block1_conv1\", 224, 3, 3, 64, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block1_conv2\", 224, 3, 64, 64, 1, 1, \"ReLU\", \"Adam\")\n",
    "# Max Pooling (2x2, stride 2) => reduces to 112x112\n",
    "\n",
    "# Block 2: 2 Conv layers + Max Pooling\n",
    "add_conv_layer_vgg(\"block2_conv1\", 112, 3, 64, 128, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block2_conv2\", 112, 3, 128, 128, 1, 1, \"ReLU\", \"Adam\")\n",
    "# Max Pooling (2x2, stride 2) => reduces to 56x56\n",
    "\n",
    "# Block 3: 3 Conv layers + Max Pooling\n",
    "add_conv_layer_vgg(\"block3_conv1\", 56, 3, 128, 256, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block3_conv2\", 56, 3, 256, 256, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block3_conv3\", 56, 3, 256, 256, 1, 1, \"ReLU\", \"Adam\")\n",
    "# Max Pooling (2x2, stride 2) => reduces to 28x28\n",
    "\n",
    "# Block 4: 3 Conv layers + Max Pooling\n",
    "add_conv_layer_vgg(\"block4_conv1\", 28, 3, 256, 512, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block4_conv2\", 28, 3, 512, 512, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block4_conv3\", 28, 3, 512, 512, 1, 1, \"ReLU\", \"Adam\")\n",
    "# Max Pooling (2x2, stride 2) => reduces to 14x14\n",
    "\n",
    "# Block 5: 3 Conv layers + Max Pooling\n",
    "add_conv_layer_vgg(\"block5_conv1\", 14, 3, 512, 512, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block5_conv2\", 14, 3, 512, 512, 1, 1, \"ReLU\", \"Adam\")\n",
    "add_conv_layer_vgg(\"block5_conv3\", 14, 3, 512, 512, 1, 1, \"ReLU\", \"Adam\")\n",
    "# Max Pooling (2x2, stride 2) => reduces to 7x7\n",
    "\n",
    "# Print out the dictionary to verify\n",
    "for layer_name, features in vgg16_conv_layers.items():\n",
    "    print(f\"{layer_name}: {features}\")\n",
    "    \n",
    "    \n",
    "# add dense layers\n",
    "add_dense_layer_vgg(\"fc1\", 25088, 4096, \"ReLU\", \"Adam\")\n",
    "add_dense_layer_vgg(\"fc2\", 4096, 4096, \"ReLU\", \"Adam\")\n",
    "add_dense_layer_vgg(\"fc3\", 4096, 10, \"Softmax\", \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/miniconda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "  1%|          | 1/100 [00:08<14:19,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 15.0384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:18<15:07,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 2.3020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:27<15:08,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 2.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:36<14:25,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 2.2998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:45<14:06,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 2.2973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:54<14:05,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 2.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:03<14:14,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: 2.2985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:12<13:53,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: 2.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:20<13:21,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: 2.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:29<13:03,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 2.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:37<12:49,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 2.2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [01:47<13:13,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: 2.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:56<13:00,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: 2.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [02:05<12:53,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: 2.2983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [02:13<12:24,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: 2.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [02:22<12:04,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: 2.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [02:30<11:52,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 2.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:39<11:53,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: 2.2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [02:48<11:46,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 2.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [02:57<11:42,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 2.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [03:05<11:28,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: 2.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [03:14<11:22,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: 2.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [03:23<11:11,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 2.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [03:31<10:54,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: 2.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [03:40<10:43,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: 2.2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [03:49<10:41,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: 2.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:58<10:43,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Loss: 2.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [04:07<10:34,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Loss: 2.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [04:15<10:11,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Loss: 2.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [04:23<09:51,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [04:31<09:42,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Loss: 2.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [04:39<09:24,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Loss: 2.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [04:48<09:22,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Loss: 2.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [04:57<09:24,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [05:05<09:14,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Loss: 2.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [05:13<08:59,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Loss: 2.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [05:22<08:48,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Loss: 2.2973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [05:30<08:36,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Loss: 2.2953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [05:38<08:28,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Loss: 2.2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [05:46<08:16,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [05:55<08:10,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Loss: 2.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [06:03<08:03,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Loss: 2.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [06:11<07:51,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Loss: 2.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [06:20<07:45,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Loss: 2.2964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [06:28<07:32,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Loss: 2.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [06:36<07:21,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [06:44<07:17,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Loss: 2.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [06:52<07:05,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Loss: 2.2982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [07:00<06:56,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Loss: 2.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [07:09<06:51,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [07:17<06:46,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Loss: 2.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [07:25<06:36,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Loss: 2.2949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [07:34<06:29,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Loss: 2.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [07:42<06:19,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Loss: 2.2959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [07:50<06:12,  8.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Loss: 2.2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [07:58<06:00,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Loss: 2.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [08:06<05:51,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Loss: 2.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [08:15<05:49,  8.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Loss: 2.2942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [08:24<05:54,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [08:34<05:57,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Loss: 2.2996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [08:43<05:46,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Loss: 2.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [08:52<05:38,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Loss: 2.2944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [09:00<05:21,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Loss: 2.2970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [09:08<05:08,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Loss: 2.2937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [09:17<04:58,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Loss: 2.2972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [09:25<04:50,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Loss: 2.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [09:34<04:44,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [09:43<04:40,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Loss: 2.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [09:51<04:25,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Loss: 2.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [10:01<04:25,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Loss: 2.2948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [10:10<04:17,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Loss: 2.2978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [10:20<04:16,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Loss: 2.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [10:28<04:04,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [10:37<03:49,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [10:45<03:35,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Loss: 2.2961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [10:53<03:25,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Loss: 2.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [11:01<03:15,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Loss: 2.2966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [11:10<03:04,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Loss: 2.2954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [11:18<02:58,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Loss: 2.2947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [11:27<02:48,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Loss: 2.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [11:36<02:43,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [11:44<02:34,  8.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Loss: 2.2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [11:52<02:23,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Loss: 2.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [12:01<02:16,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Loss: 2.2957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [12:10<02:08,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Loss: 2.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [12:19<02:01,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Loss: 2.2945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [12:28<01:56,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Loss: 2.2956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [12:37<01:48,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Loss: 2.2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [12:47<01:41,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Loss: 2.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [12:56<01:31,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Loss: 2.2986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [13:05<01:20,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [13:14<01:11,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Loss: 2.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [13:22<01:01,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Loss: 2.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [13:31<00:52,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Loss: 2.2976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [13:40<00:44,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Loss: 2.2965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [13:49<00:35,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Loss: 2.2968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [13:58<00:26,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Loss: 2.2962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [14:07<00:18,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Loss: 2.2963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [14:16<00:08,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Loss: 2.2977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [14:25<00:00,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Loss: 2.2959\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# Check if GPU is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations for the training data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),  # Convert images to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Create a random dataset (For demonstration, using FakeData)\n",
    "train_dataset = datasets.FakeData(size=dataset_size, transform=transform, image_size=(3, 224, 224))  # 1000 samples\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load VGG16 model\n",
    "model = models.vgg16(pretrained=False)  # Set pretrained=True if you want to use ImageNet weights\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)  # Change the final layer to 10 classes\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "start_time = time.time()\n",
    "for epoch in tqdm.tqdm(range(epochs)):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')\n",
    "end_time = time.time()\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken for training VGG16: 865.44 seconds\n"
     ]
    }
   ],
   "source": [
    "time_elapsed = end_time - start_time # Calculate the total time taken for training in seconds\n",
    "print(f\"Total time taken for training VGG16: {time_elapsed:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time taken for one epoch of VGG16: 8.65 seconds\n"
     ]
    }
   ],
   "source": [
    "time_for_one_epoch = time_elapsed / epochs\n",
    "print(f\"Average time taken for one epoch of VGG16: {time_for_one_epoch:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPU</th>\n",
       "      <th>Provisioning</th>\n",
       "      <th>Base Clock (MHz)</th>\n",
       "      <th>Boost Clock (MHz)</th>\n",
       "      <th>Memory Clock (MHz)</th>\n",
       "      <th>Memory (GB)</th>\n",
       "      <th>Memory Type</th>\n",
       "      <th>Memory Bus (bit)</th>\n",
       "      <th>GPU Memory Bandwidth (GB/s)</th>\n",
       "      <th>Bus</th>\n",
       "      <th>...</th>\n",
       "      <th>TMUs</th>\n",
       "      <th>ROPs</th>\n",
       "      <th>SM</th>\n",
       "      <th>TC</th>\n",
       "      <th>RT</th>\n",
       "      <th>PR</th>\n",
       "      <th>TR</th>\n",
       "      <th>FP16</th>\n",
       "      <th>FP32</th>\n",
       "      <th>FP64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L4</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>795</td>\n",
       "      <td>2040</td>\n",
       "      <td>1563</td>\n",
       "      <td>24</td>\n",
       "      <td>GDDR6</td>\n",
       "      <td>192</td>\n",
       "      <td>300</td>\n",
       "      <td>PCIe 4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>240</td>\n",
       "      <td>60</td>\n",
       "      <td>163</td>\n",
       "      <td>490</td>\n",
       "      <td>30290</td>\n",
       "      <td>30290</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P4</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>886</td>\n",
       "      <td>1114</td>\n",
       "      <td>1502</td>\n",
       "      <td>8</td>\n",
       "      <td>GDDR5</td>\n",
       "      <td>256</td>\n",
       "      <td>192</td>\n",
       "      <td>PCIe 3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>178</td>\n",
       "      <td>89</td>\n",
       "      <td>5700</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P100</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>1190</td>\n",
       "      <td>1329</td>\n",
       "      <td>715</td>\n",
       "      <td>16</td>\n",
       "      <td>HBM2</td>\n",
       "      <td>4096</td>\n",
       "      <td>732</td>\n",
       "      <td>PCIe 3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>96</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>297</td>\n",
       "      <td>19050</td>\n",
       "      <td>9526</td>\n",
       "      <td>4763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RTX4090</td>\n",
       "      <td>Local</td>\n",
       "      <td>2235</td>\n",
       "      <td>2520</td>\n",
       "      <td>1313</td>\n",
       "      <td>24</td>\n",
       "      <td>GDDR6X</td>\n",
       "      <td>384</td>\n",
       "      <td>1001</td>\n",
       "      <td>PCIe 4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>176</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>443</td>\n",
       "      <td>1290</td>\n",
       "      <td>82580</td>\n",
       "      <td>82580</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RTXA4000</td>\n",
       "      <td>Local</td>\n",
       "      <td>735</td>\n",
       "      <td>1560</td>\n",
       "      <td>1750</td>\n",
       "      <td>16</td>\n",
       "      <td>GDDR6</td>\n",
       "      <td>256</td>\n",
       "      <td>448</td>\n",
       "      <td>PCIe 4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>96</td>\n",
       "      <td>48</td>\n",
       "      <td>192</td>\n",
       "      <td>48</td>\n",
       "      <td>150</td>\n",
       "      <td>300</td>\n",
       "      <td>19170</td>\n",
       "      <td>19170</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T4</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>585</td>\n",
       "      <td>1590</td>\n",
       "      <td>1250</td>\n",
       "      <td>16</td>\n",
       "      <td>GDDR6</td>\n",
       "      <td>256</td>\n",
       "      <td>320</td>\n",
       "      <td>PCIe 3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>320</td>\n",
       "      <td>40</td>\n",
       "      <td>101</td>\n",
       "      <td>254</td>\n",
       "      <td>65130</td>\n",
       "      <td>8141</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V100</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>876</td>\n",
       "      <td>16</td>\n",
       "      <td>HBM2</td>\n",
       "      <td>4096</td>\n",
       "      <td>897</td>\n",
       "      <td>PCIe 3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GPU Provisioning  Base Clock (MHz)  Boost Clock (MHz)  \\\n",
       "0        L4        Cloud               795               2040   \n",
       "1        P4        Cloud               886               1114   \n",
       "2      P100        Cloud              1190               1329   \n",
       "3   RTX4090        Local              2235               2520   \n",
       "4  RTXA4000        Local               735               1560   \n",
       "5        T4        Cloud               585               1590   \n",
       "6      V100        Cloud              1245               1380   \n",
       "\n",
       "   Memory Clock (MHz)  Memory (GB) Memory Type  Memory Bus (bit)  \\\n",
       "0                1563           24       GDDR6               192   \n",
       "1                1502            8       GDDR5               256   \n",
       "2                 715           16        HBM2              4096   \n",
       "3                1313           24      GDDR6X               384   \n",
       "4                1750           16       GDDR6               256   \n",
       "5                1250           16       GDDR6               256   \n",
       "6                 876           16        HBM2              4096   \n",
       "\n",
       "   GPU Memory Bandwidth (GB/s)       Bus  ...  TMUs  ROPs   SM   TC   RT   PR  \\\n",
       "0                          300  PCIe 4.0  ...   240    80   60  240   60  163   \n",
       "1                          192  PCIe 3.0  ...   160    64   20    0    0   71   \n",
       "2                          732  PCIe 3.0  ...   224    96   56    0    0  127   \n",
       "3                         1001  PCIe 4.0  ...   512   176  128  512  128  443   \n",
       "4                          448  PCIe 4.0  ...   192    96   48  192   48  150   \n",
       "5                          320  PCIe 3.0  ...   160    64   40  320   40  101   \n",
       "6                          897  PCIe 3.0  ...   320   128   80  640    0  176   \n",
       "\n",
       "     TR   FP16   FP32  FP64  \n",
       "0   490  30290  30290   473  \n",
       "1   178     89   5700   178  \n",
       "2   297  19050   9526  4763  \n",
       "3  1290  82580  82580  1290  \n",
       "4   300  19170  19170   300  \n",
       "5   254  65130   8141   254  \n",
       "6   441  28260  14130  7066  \n",
       "\n",
       "[7 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_specs = pd.read_csv('../gpus/GPUs.csv')\n",
    "gpu_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_features = vgg16_conv_layers\n",
    "dense_layer_features = vgg16_dense_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = gpu_specs[gpu_specs['GPU'] == gpu_name]\n",
    "gpu = gpu.squeeze()\n",
    "gpu = pd.DataFrame([gpu] * len(conv_layer_features))\n",
    "\n",
    "conv_layer_features = pd.DataFrame.from_dict(conv_layer_features, orient='index')\n",
    "conv_layer_features = pd.concat([conv_layer_features.reset_index(drop=True), gpu.reset_index(drop=True)], axis=1)\n",
    "\n",
    "gpu = gpu_specs[gpu_specs['GPU'] == gpu_name]\n",
    "gpu = gpu.squeeze()\n",
    "gpu = pd.DataFrame([gpu] * len(dense_layer_features))\n",
    "\n",
    "dense_layer_features = pd.DataFrame.from_dict(dense_layer_features, orient='index')\n",
    "dense_layer_features = pd.concat([dense_layer_features.reset_index(drop=True), gpu.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_features['activation_fct'] = 1\n",
    "conv_layer_features['optimizer'] = 4\n",
    "conv_layer_features['precision'] = 32\n",
    "conv_layer_features['padding'] = conv_layer_features['padding'].apply(lambda x: 'valid' if x == 0 else 'same')\n",
    "conv_layer_features['use_bias'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_features['activation_fct'] = 1\n",
    "dense_layer_features['optimizer'] = 4\n",
    "dense_layer_features['precision'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batchsize</th>\n",
       "      <th>matsize</th>\n",
       "      <th>kernelsize</th>\n",
       "      <th>channels_in</th>\n",
       "      <th>channels_out</th>\n",
       "      <th>strides</th>\n",
       "      <th>padding</th>\n",
       "      <th>activation_fct</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>GPU</th>\n",
       "      <th>...</th>\n",
       "      <th>SM</th>\n",
       "      <th>TC</th>\n",
       "      <th>RT</th>\n",
       "      <th>PR</th>\n",
       "      <th>TR</th>\n",
       "      <th>FP16</th>\n",
       "      <th>FP32</th>\n",
       "      <th>FP64</th>\n",
       "      <th>precision</th>\n",
       "      <th>use_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    batchsize  matsize  kernelsize  channels_in  channels_out  strides  \\\n",
       "0          64      224           3            3            64        1   \n",
       "1          64      224           3           64            64        1   \n",
       "2          64      112           3           64           128        1   \n",
       "3          64      112           3          128           128        1   \n",
       "4          64       56           3          128           256        1   \n",
       "5          64       56           3          256           256        1   \n",
       "6          64       56           3          256           256        1   \n",
       "7          64       28           3          256           512        1   \n",
       "8          64       28           3          512           512        1   \n",
       "9          64       28           3          512           512        1   \n",
       "10         64       14           3          512           512        1   \n",
       "11         64       14           3          512           512        1   \n",
       "12         64       14           3          512           512        1   \n",
       "\n",
       "   padding  activation_fct  optimizer   GPU  ...  SM   TC  RT   PR   TR  \\\n",
       "0     same               1          4  V100  ...  80  640   0  176  441   \n",
       "1     same               1          4  V100  ...  80  640   0  176  441   \n",
       "2     same               1          4  V100  ...  80  640   0  176  441   \n",
       "3     same               1          4  V100  ...  80  640   0  176  441   \n",
       "4     same               1          4  V100  ...  80  640   0  176  441   \n",
       "5     same               1          4  V100  ...  80  640   0  176  441   \n",
       "6     same               1          4  V100  ...  80  640   0  176  441   \n",
       "7     same               1          4  V100  ...  80  640   0  176  441   \n",
       "8     same               1          4  V100  ...  80  640   0  176  441   \n",
       "9     same               1          4  V100  ...  80  640   0  176  441   \n",
       "10    same               1          4  V100  ...  80  640   0  176  441   \n",
       "11    same               1          4  V100  ...  80  640   0  176  441   \n",
       "12    same               1          4  V100  ...  80  640   0  176  441   \n",
       "\n",
       "     FP16   FP32  FP64 precision  use_bias  \n",
       "0   28260  14130  7066        32         0  \n",
       "1   28260  14130  7066        32         0  \n",
       "2   28260  14130  7066        32         0  \n",
       "3   28260  14130  7066        32         0  \n",
       "4   28260  14130  7066        32         0  \n",
       "5   28260  14130  7066        32         0  \n",
       "6   28260  14130  7066        32         0  \n",
       "7   28260  14130  7066        32         0  \n",
       "8   28260  14130  7066        32         0  \n",
       "9   28260  14130  7066        32         0  \n",
       "10  28260  14130  7066        32         0  \n",
       "11  28260  14130  7066        32         0  \n",
       "12  28260  14130  7066        32         0  \n",
       "\n",
       "[13 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batchsize</th>\n",
       "      <th>dim_input</th>\n",
       "      <th>dim_output</th>\n",
       "      <th>activation_fct</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>GPU</th>\n",
       "      <th>Provisioning</th>\n",
       "      <th>Base Clock (MHz)</th>\n",
       "      <th>Boost Clock (MHz)</th>\n",
       "      <th>Memory Clock (MHz)</th>\n",
       "      <th>...</th>\n",
       "      <th>ROPs</th>\n",
       "      <th>SM</th>\n",
       "      <th>TC</th>\n",
       "      <th>RT</th>\n",
       "      <th>PR</th>\n",
       "      <th>TR</th>\n",
       "      <th>FP16</th>\n",
       "      <th>FP32</th>\n",
       "      <th>FP64</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>25088</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>876</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>4096</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>876</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>4096</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>V100</td>\n",
       "      <td>Cloud</td>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>876</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>640</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>441</td>\n",
       "      <td>28260</td>\n",
       "      <td>14130</td>\n",
       "      <td>7066</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   batchsize  dim_input  dim_output  activation_fct  optimizer   GPU  \\\n",
       "0         64      25088        4096               1          4  V100   \n",
       "1         64       4096        4096               1          4  V100   \n",
       "2         64       4096          10               1          4  V100   \n",
       "\n",
       "  Provisioning  Base Clock (MHz)  Boost Clock (MHz)  Memory Clock (MHz)  ...  \\\n",
       "0        Cloud              1245               1380                 876  ...   \n",
       "1        Cloud              1245               1380                 876  ...   \n",
       "2        Cloud              1245               1380                 876  ...   \n",
       "\n",
       "   ROPs  SM   TC  RT   PR   TR   FP16   FP32  FP64  precision  \n",
       "0   128  80  640   0  176  441  28260  14130  7066         32  \n",
       "1   128  80  640   0  176  441  28260  14130  7066         32  \n",
       "2   128  80  640   0  176  441  28260  14130  7066         32  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_layer_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:455: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam'\n",
      " 'Adam' 'Adam' 'Adam']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'optimizer'] = self.features['optimizer'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:462: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu'\n",
      " 'relu' 'relu' 'relu']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'activation_fct'] = self.features['activation_fct'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['flops'] = (self.features['batchsize']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:478: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['flops/speed'] = self.features['flops'] / self.features['FP32']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:480: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_weights'] = (self.features['kernelsize']**2\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:485: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_in'] = (self.features['batchsize']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:489: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_out'] = (self.features['batchsize']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:493: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_total'] = self.features['memory_in'] + self.features['memory_out'] + self.features['memory_weights']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_total'] = np.where(self.features['optimizer'] != 'None', 2 * self.features['memory_total'], self.features['memory_total'])\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:501: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['use_bias'] = self.features['use_bias'].astype(int)\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:387: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Adam' 'Adam' 'Adam']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'optimizer'] = self.features['optimizer'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:394: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['relu' 'relu' 'relu']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'activation_fct'] = self.features['activation_fct'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['flops'] = (\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['flops/speed'] = self.features['flops'] / self.features['FP32']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:407: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_weights'] = self.features['dim_input'] * self.features['dim_output']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:408: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_in'] = self.features['batchsize'] * self.features['dim_input']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_out'] = self.features['batchsize'] * self.features['dim_output']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:411: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_total'] = self.features['memory_in'] + self.features['memory_out'] + self.features['memory_weights']\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:412: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['memory_total'] = np.where(self.features['optimizer'] != 'None', 2 * self.features['memory_total'], self.features['memory_total'])\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:455: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam' 'Adam'\n",
      " 'Adam' 'Adam' 'Adam']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'optimizer'] = self.features['optimizer'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:462: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu'\n",
      " 'relu' 'relu' 'relu']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'activation_fct'] = self.features['activation_fct'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:501: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.features['use_bias'] = self.features['use_bias'].astype(int)\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:387: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Adam' 'Adam' 'Adam']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'optimizer'] = self.features['optimizer'].map({0:'None',\n",
      "/home/ubuntu/dl-training-time-prediction/predict/features.py:394: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['relu' 'relu' 'relu']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  self.features.loc[:, 'activation_fct'] = self.features['activation_fct'].map({0:'None',\n"
     ]
    }
   ],
   "source": [
    "from predict.features import (\n",
    "    PreprocessConvFeatures,\n",
    "    PreprocessDenseFeatures,\n",
    ")\n",
    "\n",
    "conv_features = PreprocessConvFeatures(conv_layer_features, include_additional_features=True).features\n",
    "dense_features = PreprocessDenseFeatures(dense_layer_features, include_additional_features=True).features\n",
    "\n",
    "conv_features_less = PreprocessConvFeatures(conv_layer_features, include_additional_features=False).features\n",
    "dense_features_less = PreprocessDenseFeatures(dense_layer_features, include_additional_features=False).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Clock (MHz)</th>\n",
       "      <th>Boost Clock (MHz)</th>\n",
       "      <th>Bus_PCIe 3.0</th>\n",
       "      <th>Bus_PCIe 4.0</th>\n",
       "      <th>Cores</th>\n",
       "      <th>FP32</th>\n",
       "      <th>GPU</th>\n",
       "      <th>GPU Memory Bandwidth (GB/s)</th>\n",
       "      <th>Memory (GB)</th>\n",
       "      <th>Memory Bus (bit)</th>\n",
       "      <th>...</th>\n",
       "      <th>optimizer_Adagrad</th>\n",
       "      <th>optimizer_Adam</th>\n",
       "      <th>optimizer_None</th>\n",
       "      <th>optimizer_RMSProp</th>\n",
       "      <th>optimizer_SGD</th>\n",
       "      <th>padding_same</th>\n",
       "      <th>padding_valid</th>\n",
       "      <th>precision</th>\n",
       "      <th>strides</th>\n",
       "      <th>use_bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Base Clock (MHz)  Boost Clock (MHz)  Bus_PCIe 3.0  Bus_PCIe 4.0  Cores  \\\n",
       "0               1245               1380           1.0           0.0   5120   \n",
       "1               1245               1380           1.0           0.0   5120   \n",
       "2               1245               1380           1.0           0.0   5120   \n",
       "3               1245               1380           1.0           0.0   5120   \n",
       "4               1245               1380           1.0           0.0   5120   \n",
       "5               1245               1380           1.0           0.0   5120   \n",
       "6               1245               1380           1.0           0.0   5120   \n",
       "7               1245               1380           1.0           0.0   5120   \n",
       "8               1245               1380           1.0           0.0   5120   \n",
       "9               1245               1380           1.0           0.0   5120   \n",
       "10              1245               1380           1.0           0.0   5120   \n",
       "11              1245               1380           1.0           0.0   5120   \n",
       "12              1245               1380           1.0           0.0   5120   \n",
       "\n",
       "     FP32   GPU  GPU Memory Bandwidth (GB/s)  Memory (GB)  Memory Bus (bit)  \\\n",
       "0   14130  V100                          897           16              4096   \n",
       "1   14130  V100                          897           16              4096   \n",
       "2   14130  V100                          897           16              4096   \n",
       "3   14130  V100                          897           16              4096   \n",
       "4   14130  V100                          897           16              4096   \n",
       "5   14130  V100                          897           16              4096   \n",
       "6   14130  V100                          897           16              4096   \n",
       "7   14130  V100                          897           16              4096   \n",
       "8   14130  V100                          897           16              4096   \n",
       "9   14130  V100                          897           16              4096   \n",
       "10  14130  V100                          897           16              4096   \n",
       "11  14130  V100                          897           16              4096   \n",
       "12  14130  V100                          897           16              4096   \n",
       "\n",
       "    ...  optimizer_Adagrad  optimizer_Adam  optimizer_None  optimizer_RMSProp  \\\n",
       "0   ...                0.0             1.0             0.0                0.0   \n",
       "1   ...                0.0             1.0             0.0                0.0   \n",
       "2   ...                0.0             1.0             0.0                0.0   \n",
       "3   ...                0.0             1.0             0.0                0.0   \n",
       "4   ...                0.0             1.0             0.0                0.0   \n",
       "5   ...                0.0             1.0             0.0                0.0   \n",
       "6   ...                0.0             1.0             0.0                0.0   \n",
       "7   ...                0.0             1.0             0.0                0.0   \n",
       "8   ...                0.0             1.0             0.0                0.0   \n",
       "9   ...                0.0             1.0             0.0                0.0   \n",
       "10  ...                0.0             1.0             0.0                0.0   \n",
       "11  ...                0.0             1.0             0.0                0.0   \n",
       "12  ...                0.0             1.0             0.0                0.0   \n",
       "\n",
       "    optimizer_SGD  padding_same  padding_valid  precision  strides  use_bias  \n",
       "0             0.0           1.0            0.0         32        1         0  \n",
       "1             0.0           1.0            0.0         32        1         0  \n",
       "2             0.0           1.0            0.0         32        1         0  \n",
       "3             0.0           1.0            0.0         32        1         0  \n",
       "4             0.0           1.0            0.0         32        1         0  \n",
       "5             0.0           1.0            0.0         32        1         0  \n",
       "6             0.0           1.0            0.0         32        1         0  \n",
       "7             0.0           1.0            0.0         32        1         0  \n",
       "8             0.0           1.0            0.0         32        1         0  \n",
       "9             0.0           1.0            0.0         32        1         0  \n",
       "10            0.0           1.0            0.0         32        1         0  \n",
       "11            0.0           1.0            0.0         32        1         0  \n",
       "12            0.0           1.0            0.0         32        1         0  \n",
       "\n",
       "[13 rows x 43 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Clock (MHz)</th>\n",
       "      <th>Boost Clock (MHz)</th>\n",
       "      <th>Bus_PCIe 3.0</th>\n",
       "      <th>Bus_PCIe 4.0</th>\n",
       "      <th>Cores</th>\n",
       "      <th>FP32</th>\n",
       "      <th>GPU</th>\n",
       "      <th>GPU Memory Bandwidth (GB/s)</th>\n",
       "      <th>Memory (GB)</th>\n",
       "      <th>Memory Bus (bit)</th>\n",
       "      <th>...</th>\n",
       "      <th>memory_out</th>\n",
       "      <th>memory_total</th>\n",
       "      <th>memory_weights</th>\n",
       "      <th>optimizer_Adadelta</th>\n",
       "      <th>optimizer_Adagrad</th>\n",
       "      <th>optimizer_Adam</th>\n",
       "      <th>optimizer_None</th>\n",
       "      <th>optimizer_RMSProp</th>\n",
       "      <th>optimizer_SGD</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>262144</td>\n",
       "      <td>209256448</td>\n",
       "      <td>102760448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>262144</td>\n",
       "      <td>34603008</td>\n",
       "      <td>16777216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1245</td>\n",
       "      <td>1380</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5120</td>\n",
       "      <td>14130</td>\n",
       "      <td>V100</td>\n",
       "      <td>897</td>\n",
       "      <td>16</td>\n",
       "      <td>4096</td>\n",
       "      <td>...</td>\n",
       "      <td>640</td>\n",
       "      <td>607488</td>\n",
       "      <td>40960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Base Clock (MHz)  Boost Clock (MHz)  Bus_PCIe 3.0  Bus_PCIe 4.0  Cores  \\\n",
       "0              1245               1380           1.0           0.0   5120   \n",
       "1              1245               1380           1.0           0.0   5120   \n",
       "2              1245               1380           1.0           0.0   5120   \n",
       "\n",
       "    FP32   GPU  GPU Memory Bandwidth (GB/s)  Memory (GB)  Memory Bus (bit)  \\\n",
       "0  14130  V100                          897           16              4096   \n",
       "1  14130  V100                          897           16              4096   \n",
       "2  14130  V100                          897           16              4096   \n",
       "\n",
       "   ...  memory_out  memory_total  memory_weights  optimizer_Adadelta  \\\n",
       "0  ...      262144     209256448       102760448                 0.0   \n",
       "1  ...      262144      34603008        16777216                 0.0   \n",
       "2  ...         640        607488           40960                 0.0   \n",
       "\n",
       "   optimizer_Adagrad  optimizer_Adam  optimizer_None  optimizer_RMSProp  \\\n",
       "0                0.0             1.0             0.0                0.0   \n",
       "1                0.0             1.0             0.0                0.0   \n",
       "2                0.0             1.0             0.0                0.0   \n",
       "\n",
       "   optimizer_SGD  precision  \n",
       "0            0.0         32  \n",
       "1            0.0         32  \n",
       "2            0.0         32  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_features = conv_features.drop(columns=['GPU'])\n",
    "dense_features = dense_features.drop(columns=['GPU'])\n",
    "\n",
    "conv_features_less = conv_features_less.drop(columns=['GPU'])\n",
    "dense_features_less = dense_features_less.drop(columns=['GPU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_conv_less = conv_wo_features_predictor.predict(conv_features_less)\n",
    "predicted_dense_less = dense_wo_features_predictor.predict(dense_features_less)\n",
    "\n",
    "predicted_conv_less = sum(predicted_conv_less * (dataset_size / batch_size)) / 1000\n",
    "predicted_dense_less = sum(predicted_dense_less * (dataset_size / batch_size)) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_conv = conv_predictor.predict(conv_features)\n",
    "predicted_dense = dense_predictor.predict(dense_features)\n",
    "\n",
    "predicted_conv = sum(predicted_conv * (dataset_size / batch_size)) / 1000\n",
    "predicted_dense = sum(predicted_dense * (dataset_size / batch_size)) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_e2e = predicted_conv + predicted_dense\n",
    "predicted_e2e_less = predicted_conv_less + predicted_dense_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in prediction with all features for VGG16: 13.96%\n",
      "Predicted time for one epoch will all features for VGG16: 7.45 seconds\n",
      "Actual time for one epoch: 8.65 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Error in prediction with all features for VGG16: {abs(predicted_e2e - time_for_one_epoch) / time_for_one_epoch * 100:.2f}%\")\n",
    "print(f'Predicted time for one epoch will all features for VGG16: {predicted_e2e:.2f} seconds')\n",
    "print(f'Actual time for one epoch: {time_for_one_epoch:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in prediction with raw features for VGG16: 78.87%\n",
      "Predicted time for one epoch with raw features for VGG16: 1.83 seconds\n",
      "Actual time for one epoch: 8.65 seconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Error in prediction with raw features for VGG16: {abs(predicted_e2e_less - time_for_one_epoch) / time_for_one_epoch * 100:.2f}%\")\n",
    "print(f'Predicted time for one epoch with raw features for VGG16: {predicted_e2e_less:.2f} seconds')\n",
    "print(f'Actual time for one epoch: {time_for_one_epoch:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
